{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not infer format, so each element will be parsed individually\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1:  EXTRACT DATA FOR 2016, 2018, and 2019 FIRES \n",
    "\n",
    "# Define path to the source files\n",
    "file_2016 = 'Resources/CAL_FireStats/2016-wildfire-activity-stats.xlsx'\n",
    "file_2018 = 'Resources/CAL_FireStats/2018-wildfire-activity-stats.xlsx'\n",
    "file_2019 = 'Resources/CAL_FireStats/2019-wildfire-activity-stats.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sheets to be read (all these files contain needed information on the same pages)\n",
    "sheets = ['table_page_13', 'table_page_14', 'table_page_15', 'table_page_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                      'Dest.', 'Dam.', 'Fire', 'Civil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and process the data from the Excel files\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    # Initiate an empty Data Frame\n",
    "    extracted_data = pd.DataFrame()\n",
    "    # Set a 'for' loop to go through identified path, sheets, and columns\n",
    "    # skip the 1st row as it does not contain iseful information\n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        # Add the data to an existing collection of data, Index=True to re-number the rows after adding a new data\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Dest.', 'Dam.', 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Dest.'] = pd.to_numeric(extracted_data['Dest.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Dam.'] = pd.to_numeric(extracted_data['Dam.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres', 'Dest.': 'Strux_Destr', 'Dam.': 'Strux_Dmgd', \n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                     'Strux_Destr', 'Strux_Dmgd', 'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    # Return the processed data as a DataFrame so it can be used outside the function\n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for 2016, 2018, 2019 years\n",
    "fires_2016 = load_wildfire_data(file_2016, sheets, columns_to_extract)\n",
    "fires_2018 = load_wildfire_data(file_2018, sheets, columns_to_extract)\n",
    "fires_2019 = load_wildfire_data(file_2019, sheets, columns_to_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data from 2016, 2018, and 2019 into one DataFrame\n",
    "fires_2016_2018_2019_data = pd.concat([fires_2016, fires_2018, fires_2019], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 Fire Data:\n",
      "      County Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0   MONTEREY      METZ 2016-05-22 2016-05-25  3,876            0           0   \n",
      "1  SAN DIEGO  BORDER 3 2016-06-19 2016-07-01  7,609           16           3   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       4.0  \n",
      "1          0             2      13.0  \n",
      "--------------------------------------\n",
      "\n",
      "2018 Fire Data:\n",
      "      County  Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0       INYO     MOFFAT 2018-04-19 2018-04-24  1,065            0           0   \n",
      "1     MERCED       NEES 2018-05-02 2018-05-02  1,756            0           0   \n",
      "2  RIVERSIDE  PATTERSON 2018-05-17 2018-05-18  1,261            0           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       6.0  \n",
      "1          0             0       1.0  \n",
      "2          0             0       2.0  \n",
      "--------------------------------------\n",
      "\n",
      "2019 Fire Data:\n",
      "            County Fire Name      Start  Contained  Acres  Strux_Destr  \\\n",
      "0        RIVERSIDE   LINCOLN 2019-03-15 2019-03-20    560            0   \n",
      "1  SAN LUIS OBISPO   BELMONT 2019-05-29 2019-05-29    835            0   \n",
      "2  SAN LUIS OBISPO   BOULDER 2019-06-05 2019-06-05  1,075            0   \n",
      "\n",
      "   Strux_Dmgd  Deaths_FF  Deaths_Civil  Duration  \n",
      "0           0          0             0       6.0  \n",
      "1           0          0             0       1.0  \n",
      "2           0          0             0       1.0  \n",
      "--------------------------------------\n",
      "\n",
      "Combined Fire Data (2016, 2018, 2019):\n",
      "      County Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0   MONTEREY      METZ 2016-05-22 2016-05-25  3,876            0           0   \n",
      "1  SAN DIEGO  BORDER 3 2016-06-19 2016-07-01  7,609           16           3   \n",
      "2     MERCED  DINOSAUR 2016-06-25 2016-06-26  1,246            0           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       4.0  \n",
      "1          0             2      13.0  \n",
      "2          0             0       2.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first two rows of the 2016, 2018, 2019, and combined dataframes to check the results\n",
    "print(\"2016 Fire Data:\")\n",
    "print(fires_2016.head(2))\n",
    "print(\"--------------------------------------\")\n",
    "print(\"\\n2018 Fire Data:\")\n",
    "print(fires_2018.head(3))\n",
    "print(\"--------------------------------------\")\n",
    "print(\"\\n2019 Fire Data:\")\n",
    "print(fires_2019.head(3))\n",
    "print(\"--------------------------------------\")\n",
    "print(\"\\nCombined Fire Data (2016, 2018, 2019):\")\n",
    "print(fires_2016_2018_2019_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data Frames to 'Outputs' folder\n",
    "fires_2016.to_csv('Outputs/2016_wildfire_data.csv', index=False)\n",
    "fires_2018.to_csv('Outputs/2018_wildfire_data.csv', index=False)\n",
    "fires_2019.to_csv('Outputs/2019_wildfire_data.csv', index=False)\n",
    "fires_2016_2018_2019_data.to_csv('Outputs/2016_2018_2019_wildfire_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 Fire Data:\n",
      "   County  Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0  FRESNO      JAYNE 2017-04-20 2017-04-21  4,532            0           0   \n",
      "1  FRESNO  EL DORADO 2017-04-28 2017-04-28    750            0           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       2.0  \n",
      "1          0             0       1.0  \n"
     ]
    }
   ],
   "source": [
    "#  PART 2: EXTRACT DATA FOR 2017 FIRES:\n",
    "\n",
    "# Define path to the source file of fires 2017\n",
    "file_2017 = 'Resources/CAL_FireStats/2017-wildfire-activity-stats.xlsx'\n",
    "# Define the sheets to be read thta contain needed information (different number of pages than 2016, 2018-2019 files)\n",
    "sheets = ['table_page_13', 'table_page_14', 'table_page_15', 'table_page_16', 'table_page_17', 'table_page_18']\n",
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                      'Dest.', 'Dam.', 'Fire', 'Civil']\n",
    "# Function to load and process the data from the given Excel file\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    extracted_data = pd.DataFrame()\n",
    "    \n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Dest.', 'Dam.', 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Dest.'] = pd.to_numeric(extracted_data['Dest.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Dam.'] = pd.to_numeric(extracted_data['Dam.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres', 'Dest.': 'Strux_Destr', 'Dam.': 'Strux_Dmgd', \n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                     'Strux_Destr', 'Strux_Dmgd', 'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    \n",
    "    return extracted_data\n",
    "# Load data for 2017\n",
    "fires_2017 = load_wildfire_data(file_2017, sheets, columns_to_extract)\n",
    "# Display the first two rows of the data frame\n",
    "print(\"2017 Fire Data:\")\n",
    "print(fires_2017.head(2))\n",
    "# Save Data Frames to 'Outputs' folder\n",
    "fires_2017.to_csv('Outputs/2017_wildfire_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015 Fire Data:\n",
      "      County Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0       INYO     ROUND 2015-02-06 2015-02-13  7,000           43           5   \n",
      "1  RIVERSIDE   HIGHWAY 2015-04-18 2015-04-24  1,049            0           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       8.0  \n",
      "1          0             0       7.0  \n"
     ]
    }
   ],
   "source": [
    "#  PART 3: EXTRACT DATA FOR 2015 FIRES\n",
    "\n",
    "# Define path to the source file of fires 2015\n",
    "file_2015 = 'Resources/CAL_FireStats/2015-wildfire-activity-stats.xlsx'\n",
    "# Define the sheets to be read thta contain needed information (different number of pages than 2016, 2018-2019 files)\n",
    "sheets = ['table_page_13', 'table_page_14', 'table_page_15']\n",
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                      'Dest.', 'Dam.', 'Fire', 'Civil']\n",
    "# Function to load and process the data from the given Excel file\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    extracted_data = pd.DataFrame()\n",
    "    \n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Dest.', 'Dam.', 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Dest.'] = pd.to_numeric(extracted_data['Dest.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Dam.'] = pd.to_numeric(extracted_data['Dam.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres', 'Dest.': 'Strux_Destr', 'Dam.': 'Strux_Dmgd', \n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                     'Strux_Destr', 'Strux_Dmgd', 'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    \n",
    "    return extracted_data\n",
    "# Load data for 2017\n",
    "fires_2015 = load_wildfire_data(file_2015, sheets, columns_to_extract)\n",
    "# Display the first two rows of the data frame\n",
    "print(\"2015 Fire Data:\")\n",
    "print(fires_2015.head(2))\n",
    "# Save Data Frames to 'Outputs' folder\n",
    "fires_2015.to_csv('Outputs/2015_wildfire_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PART 4:  Combine the data from 2016, 2018, and 2019 with data from 2015, and 2017\n",
    "\n",
    "fires_2015_2019= pd.concat([fires_2015, fires_2017, fires_2016_2018_2019_data], ignore_index=True)\n",
    "                           \n",
    "# Save Data Frames to 'Outputs' folder\n",
    "fires_2015_2019.to_csv('Outputs/2015_2019_wildfire_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where 'Start' is after 'Cont.':\n",
      "     County Fire Name      Start  Contained Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "278  TEHAMA      DALE 2028-07-09 2018-07-09   856            0           0   \n",
      "\n",
      "     Deaths_FF  Deaths_Civil  Duration  \n",
      "278          0             0   -3652.0  \n"
     ]
    }
   ],
   "source": [
    "# PART 5: FINAL CLEAN UP OF THE COMBINED DATA\n",
    "\n",
    "# Sort the final data by the start and then contained dates (in case of multiple fires started on the same date)\n",
    "fires_2015_2019_sorted = fires_2015_2019.sort_values(by=['Start', 'Contained'], ascending=True)\n",
    "\n",
    "# Remove rows where 'County' column is empty (NaN or empty strings) to remove summary lines from the data\n",
    "fires_2015_2019_filtered = fires_2015_2019_sorted.dropna(subset=['County']) # Remove Nan values\n",
    "fires_2015_2019_filtered = fires_2015_2019_filtered[fires_2015_2019_filtered['County'].str.strip() != ''] #Remove empty lines\n",
    "\n",
    "# Identify where 'Start' is after 'Cont.'\n",
    "incorrect_dates = fires_2015_2019_filtered[fires_2015_2019_filtered['Start'] > fires_2015_2019_filtered['Contained']]\n",
    "\n",
    "# Display the rows where 'Start' is after 'Cont.'\n",
    "if not incorrect_dates.empty:\n",
    "    print(\"Rows where 'Start' is after 'Cont.':\")\n",
    "    print(incorrect_dates)\n",
    "else:\n",
    "        print(\"No rows found where 'Start' is after 'Cont.'\")\n",
    "\n",
    "# Update 'Start' to be equal to 'Cont.' where 'Start' is after 'Cont.' as in it seems like simplie mistype in the year\n",
    "fires_2015_2019_filtered.loc[fires_2015_2019_filtered['Start'] > fires_2015_2019_filtered['Contained'], 'Start'] = fires_2015_2019_filtered['Contained']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors were found in fire duration count.\n",
      "         Start  Contained Duration\n",
      "365 2019-10-31 2019-11-03   4 days\n",
      "367 2019-10-31 2019-11-06   7 days\n",
      "368 2019-11-03 2019-11-06   4 days\n",
      "369 2019-11-25 2019-11-25   1 days\n",
      "397 2019-11-25 2019-12-13  19 days\n"
     ]
    }
   ],
   "source": [
    "# Sort the cleaned data by 'Start' and 'Contained' dates\n",
    "fires_2015_2019_cleaned = fires_2015_2019_filtered.sort_values(by=['Start', 'Contained'], ascending=True)\n",
    "\n",
    "# Calculate the duration of the fire (assuming 'Contained' is the end date and 'Start' is the start date)\n",
    "fires_2015_2019_cleaned['Duration'] = fires_2015_2019_cleaned['Contained'] - fires_2015_2019_cleaned['Start']\n",
    "\n",
    "# To add one day to the duration to include the start date fully, you can do this:\n",
    "fires_2015_2019_cleaned['Duration'] = fires_2015_2019_cleaned['Duration'] + pd.Timedelta(days=1)\n",
    "\n",
    "\n",
    "# Display the rows where 'Duration' is negative\n",
    "negative_duration = fires_2015_2019_cleaned[fires_2015_2019_cleaned['Duration'] < pd.Timedelta(0)]\n",
    "if not negative_duration.empty:\n",
    "    print(\"Duration is incorrect:\")\n",
    "    print(negative_duration)\n",
    "else:\n",
    "    print(\"No errors were found in fire duration count.\")\n",
    "\n",
    "# Print the cleaned data to verify no errors\n",
    "print(fires_2015_2019_cleaned[['Start', 'Contained', 'Duration']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspiciously long durations:\n",
      "     County Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "340  COLUSA      SAND 2019-06-08 2020-06-15  2,220            4           0   \n",
      "\n",
      "     Deaths_FF  Deaths_Civil Duration  \n",
      "340          0             0 374 days  \n"
     ]
    }
   ],
   "source": [
    "# Verifying if there are any other errors in the data (like suspiciously long fires)\n",
    "\n",
    "# Define a timedelta representing 150 days\n",
    "threshold_duration = pd.Timedelta(days=150)\n",
    "# Find a d display if any fires lasted longer than 150 days according to our data\n",
    "long_durations = fires_2015_2019_cleaned[fires_2015_2019_cleaned['Duration'] > threshold_duration]\n",
    "print(\"Suspiciously long durations:\")\n",
    "print(long_durations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected record:\n",
      "County                       COLUSA\n",
      "Fire Name                      SAND\n",
      "Start           2019-06-08 00:00:00\n",
      "Contained       2019-06-15 00:00:00\n",
      "Acres                         2,220\n",
      "Strux_Destr                       4\n",
      "Strux_Dmgd                        0\n",
      "Deaths_FF                         0\n",
      "Deaths_Civil                      0\n",
      "Duration          374 days 00:00:00\n",
      "Name: 340, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# According to Google SAND fired was contained on 2019-06-15, 1 year earlier than our data shows.\n",
    "# Correct the year in the 'Contained' column to 2019\n",
    "fires_2015_2019_cleaned.loc[340, 'Contained'] = fires_2015_2019_cleaned.loc[340, 'Contained'].replace(year=2019)\n",
    "# Verify the updated record\n",
    "print(\"Corrected record:\")\n",
    "print(fires_2015_2019_cleaned.loc[340])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timedelta64[ns]\n",
      "Updated record with recalculated Duration:\n",
      "County                       COLUSA\n",
      "Fire Name                      SAND\n",
      "Start           2019-06-08 00:00:00\n",
      "Contained       2019-06-15 00:00:00\n",
      "Acres                         2,220\n",
      "Strux_Destr                       4\n",
      "Strux_Dmgd                        0\n",
      "Deaths_FF                         0\n",
      "Deaths_Civil                      0\n",
      "Duration            8 days 00:00:00\n",
      "Name: 340, dtype: object\n",
      "timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Duration' column to timedelta if it is not already\n",
    "fires_2015_2019_cleaned['Duration'] = pd.to_timedelta(fires_2015_2019_cleaned['Duration'], errors='coerce')\n",
    "\n",
    "# Check the dtype to verify the conversion\n",
    "print(fires_2015_2019_cleaned['Duration'].dtype)\n",
    "\n",
    "# Recalculate the 'Duration' for the corrected record\n",
    "duration = fires_2015_2019_cleaned.loc[340, 'Contained'] - fires_2015_2019_cleaned.loc[340, 'Start'] + pd.Timedelta(days=1)\n",
    "\n",
    "# Update the 'Duration' column with the recalculated duration\n",
    "fires_2015_2019_cleaned.at[340, 'Duration'] = duration\n",
    "\n",
    "# Print the updated record to verify the recalculated 'Duration'\n",
    "print(\"Updated record with recalculated Duration:\")\n",
    "print(fires_2015_2019_cleaned.loc[340])\n",
    "print(fires_2015_2019_cleaned['Duration'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       County Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "26       MONO  VAN DYKE 2015-02-06 2015-02-10    509            0           0   \n",
      "0        INYO     ROUND 2015-02-06 2015-02-13  7,000           43           5   \n",
      "1   RIVERSIDE   HIGHWAY 2015-04-18 2015-04-24  1,049            0           0   \n",
      "27  SAN DIEGO      CARL 2015-04-28 2015-04-29  4,000            0           0   \n",
      "28  SAN DIEGO    MORTAR 2015-04-28 2015-04-29    800            0           0   \n",
      "\n",
      "    Deaths_FF  Deaths_Civil Duration  Duration_Days  \n",
      "26          0             0   5 days              5  \n",
      "0           0             0   8 days              8  \n",
      "1           0             0   7 days              7  \n",
      "27          0             0   2 days              2  \n",
      "28          0             0   2 days              2  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'Duration' to timedelta format\n",
    "fires_2015_2019_cleaned['Duration'] = pd.to_timedelta(fires_2015_2019_cleaned['Duration'])\n",
    "\n",
    "# Calculate the duration in days and convert it to an integer\n",
    "fires_2015_2019_cleaned['Duration_Days'] = fires_2015_2019_cleaned['Duration'].dt.days\n",
    "\n",
    "# If you want to format the 'Duration' as a string like 'X days HH:MM:SS'\n",
    "# fires_2015_2019_cleaned['Duration_Str'] = fires_2015_2019_cleaned['Duration'].apply(\n",
    "    #lambda x: f\"{x.days} days {x.components.hours:02}:{x.components.minutes:02}:{x.components.seconds:02}\"\n",
    "#)\n",
    "\n",
    "# Print the cleaned data to check results\n",
    "print(fires_2015_2019_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            County  Fire Name      Start  Contained  Acres  Strux_Destr  \\\n",
      "365      RIVERSIDE       HILL 2019-10-31 2019-11-03    628            0   \n",
      "367        VENTURA      MARIA 2019-10-31 2019-11-06  9,999            4   \n",
      "368         TEHAMA      RANCH 2019-11-03 2019-11-06  2,534            0   \n",
      "369         PLACER  FOOTHILLS 2019-11-25 2019-11-25    308            0   \n",
      "397  SANTA BARBARA       CAVE 2019-11-25 2019-12-13  3,126            0   \n",
      "\n",
      "     Strux_Dmgd  Deaths_FF  Deaths_Civil Duration  Duration_Days  \n",
      "365           0          0             0   4 days              4  \n",
      "367           0          0             0   7 days              7  \n",
      "368           1          0             0   4 days              4  \n",
      "369           0          0             0   1 days              1  \n",
      "397           1          0             0  19 days             19  \n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned data to the \"Outputs\" folder\n",
    "fires_2015_2019_cleaned.to_csv('Outputs/fires_2015_2019_cleaned.csv', index=False)\n",
    "\n",
    "# Print the cleaned data to check\n",
    "print(fires_2015_2019_cleaned.tail(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
