{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Could not infer format, so each element will be parsed individually\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data was extracted from PDF files, with each page saved in a separate tab in Excel.\n",
    "# The page numbers and tab names vary between Excel files.\n",
    "# Therefore, we divided the process into several steps based on the data structure.\n",
    "# For convenience, files with matching tab names and the same number of relevant pages were grouped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1:  EXTRACT DATA FOR 2011 - 2013, 2016, and 2018 - 2019 FIRES \n",
    "\n",
    "# Define path to the source files\n",
    "file_2011 = 'Resources/CAL_FireStats/2011-wildfire-activity-stats.xlsx'\n",
    "file_2012 = 'Resources/CAL_FireStats/2012-wildfire-activity-stats.xlsx'\n",
    "file_2013 = 'Resources/CAL_FireStats/2013-wildfire-activity-stats.xlsx'\n",
    "file_2016 = 'Resources/CAL_FireStats/2016-wildfire-activity-stats.xlsx'\n",
    "file_2018 = 'Resources/CAL_FireStats/2018-wildfire-activity-stats.xlsx'\n",
    "file_2019 = 'Resources/CAL_FireStats/2019-wildfire-activity-stats.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sheets to be read (all these files contain needed information on the same pages)\n",
    "sheets = ['table_page_13', 'table_page_14', 'table_page_15', 'table_page_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                      'Dest.', 'Dam.', 'Fire', 'Civil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and process the data from the Excel files\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    # Initiate an empty Data Frame\n",
    "    extracted_data = pd.DataFrame()\n",
    "    # Set a 'for' loop to go through identified path, sheets, and columns\n",
    "    # skip the 1st row as it does not contain iseful information\n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        # Add the data to an existing collection of data, Index=True to re-number the rows after adding a new data\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Dest.', 'Dam.', 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Dest.'] = pd.to_numeric(extracted_data['Dest.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Dam.'] = pd.to_numeric(extracted_data['Dam.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres', 'Dest.': 'Strux_Destr', 'Dam.': 'Strux_Dmgd', \n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                     'Strux_Destr', 'Strux_Dmgd', 'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    # Return the processed data as a DataFrame so it can be used outside the function\n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for 2016, 2018, 2019 years\n",
    "fires_2011 = load_wildfire_data(file_2011, sheets, columns_to_extract)\n",
    "fires_2012 = load_wildfire_data(file_2012, sheets, columns_to_extract)\n",
    "fires_2013 = load_wildfire_data(file_2013, sheets, columns_to_extract)\n",
    "fires_2016 = load_wildfire_data(file_2016, sheets, columns_to_extract)\n",
    "fires_2018 = load_wildfire_data(file_2018, sheets, columns_to_extract)\n",
    "fires_2019 = load_wildfire_data(file_2019, sheets, columns_to_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data from 2016, 2018, and 2019 into one DataFrame\n",
    "fires_2011_2012_2013_2016_2018_2019_data = pd.concat([fires_2011, fires_2012, fires_2013, fires_2016, fires_2018, fires_2019], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 Fire Data:\n",
      "  County  Fire Name      Start  Contained Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0   INYO  WINTERTON 2011-03-09 2011-03-09   395            0           0   \n",
      "1   INYO     CENTER 2011-03-18 2011-03-23   850           19           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       1.0  \n",
      "1          0             0       6.0  \n",
      "--------------------------------------\n",
      "\n",
      "Combined Fire Data (2011-2013,2016, 2018-2019):\n",
      "     County  Fire Name      Start  Contained Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0      INYO  WINTERTON 2011-03-09 2011-03-09   395            0           0   \n",
      "1      INYO     CENTER 2011-03-18 2011-03-23   850           19           0   \n",
      "2  MONTEREY       METZ 2011-05-12 2011-05-14   832            0           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       1.0  \n",
      "1          0             0       6.0  \n",
      "2          0             0       3.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first two rows of the 2011 and combined dataframes to check the results\n",
    "print(\"2011 Fire Data:\")\n",
    "print(fires_2011.head(2))\n",
    "print(\"--------------------------------------\")\n",
    "print(\"\\nCombined Fire Data (2011-2013,2016, 2018-2019):\")\n",
    "print(fires_2011_2012_2013_2016_2018_2019_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 Fire Data:\n",
      "   County  Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0  FRESNO      JAYNE 2017-04-20 2017-04-21  4,532            0           0   \n",
      "1  FRESNO  EL DORADO 2017-04-28 2017-04-28    750            0           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       2.0  \n",
      "1          0             0       1.0  \n"
     ]
    }
   ],
   "source": [
    "#  PART 2: EXTRACT DATA FOR 2017 FIRES:\n",
    "\n",
    "# Define path to the source file of fires 2017\n",
    "file_2017 = 'Resources/CAL_FireStats/2017-wildfire-activity-stats.xlsx'\n",
    "# Define the sheets to be read thta contain needed information (different number of pages than 2016, 2018-2019 files)\n",
    "sheets = ['table_page_13', 'table_page_14', 'table_page_15', 'table_page_16', 'table_page_17', 'table_page_18']\n",
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                      'Dest.', 'Dam.', 'Fire', 'Civil']\n",
    "# Function to load and process the data from the given Excel file\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    extracted_data = pd.DataFrame()\n",
    "    \n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Dest.', 'Dam.', 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Dest.'] = pd.to_numeric(extracted_data['Dest.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Dam.'] = pd.to_numeric(extracted_data['Dam.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres', 'Dest.': 'Strux_Destr', 'Dam.': 'Strux_Dmgd', \n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                     'Strux_Destr', 'Strux_Dmgd', 'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    \n",
    "    return extracted_data\n",
    "# Load data for 2017\n",
    "fires_2017 = load_wildfire_data(file_2017, sheets, columns_to_extract)\n",
    "# Display the first two rows of the data frame\n",
    "print(\"2017 Fire Data:\")\n",
    "print(fires_2017.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 Fire Data:\n",
      "      County Fire Name      Start  Contained Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0   HUMBOLDT       RED 2014-01-04 2014-01-12   333            0           0   \n",
      "1  RIVERSIDE    PIERCE 2014-03-15 2014-03-16   350            0           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       9.0  \n",
      "1          0             0       2.0  \n",
      "--------------------------------------------\n",
      "2015 Fire Data:\n",
      "      County Fire Name      Start  Contained  Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0       INYO     ROUND 2015-02-06 2015-02-13  7,000           43           5   \n",
      "1  RIVERSIDE   HIGHWAY 2015-04-18 2015-04-24  1,049            0           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       8.0  \n",
      "1          0             0       7.0  \n"
     ]
    }
   ],
   "source": [
    "#  PART 3: EXTRACT DATA FOR 2014 - 2015 FIRES\n",
    "\n",
    "# Define path to the source file of fires 2014 - 2015\n",
    "file_2014 = 'Resources/CAL_FireStats/2014-wildfire-activity-stats.xlsx'\n",
    "file_2015 = 'Resources/CAL_FireStats/2015-wildfire-activity-stats.xlsx'\n",
    "# Define the sheets to be read thta contain needed information (different number of pages than 2016, 2018-2019 files)\n",
    "sheets = ['table_page_13', 'table_page_14', 'table_page_15']\n",
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                      'Dest.', 'Dam.', 'Fire', 'Civil']\n",
    "# Function to load and process the data from the given Excel file\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    extracted_data = pd.DataFrame()\n",
    "    \n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Dest.', 'Dam.', 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Dest.'] = pd.to_numeric(extracted_data['Dest.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Dam.'] = pd.to_numeric(extracted_data['Dam.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres', 'Dest.': 'Strux_Destr', 'Dam.': 'Strux_Dmgd', \n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                     'Strux_Destr', 'Strux_Dmgd', 'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    \n",
    "    return extracted_data\n",
    "# Load data for 2014 - 2015\n",
    "fires_2014 = load_wildfire_data(file_2014, sheets, columns_to_extract)\n",
    "fires_2015 = load_wildfire_data(file_2015, sheets, columns_to_extract)\n",
    "# Display the first two rows of the data frame\n",
    "print(\"2014 Fire Data:\")\n",
    "print(fires_2014.head(2))\n",
    "print(\"--------------------------------------------\")\n",
    "print(\"2015 Fire Data:\")\n",
    "print(fires_2015.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 Fire Data:\n",
      "      County Fire Name      Start  Contained Acres  Strux_Destr  Strux_Dmgd  \\\n",
      "0  Riverside    PEDLEY 2010-05-12 2010-05-13   850            0           0   \n",
      "1       Kern    METZEN 2010-05-15 2010-05-15   360            1           0   \n",
      "\n",
      "   Deaths_FF  Deaths_Civil  Duration  \n",
      "0          0             0       2.0  \n",
      "1          0             0       1.0  \n"
     ]
    }
   ],
   "source": [
    "#  PART 4: EXTRACT DATA FOR 2010 FIRES:\n",
    "\n",
    "# Define path to the source file of fires 2010\n",
    "file_2010 = 'Resources/CAL_FireStats/2010-wildfire-activity-stats.xlsx'\n",
    "# Define the sheets to be read thta contain needed information (different number of pages than 2016, 2018-2019 files)\n",
    "sheets = ['table_page_11', 'table_page_12']\n",
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                      'Dest.', 'Dam.', 'Fire', 'Civil']\n",
    "# Function to load and process the data from the given Excel file\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    extracted_data = pd.DataFrame()\n",
    "    \n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Dest.', 'Dam.', 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Dest.'] = pd.to_numeric(extracted_data['Dest.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Dam.'] = pd.to_numeric(extracted_data['Dam.'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres', 'Dest.': 'Strux_Destr', 'Dam.': 'Strux_Dmgd', \n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                     'Strux_Destr', 'Strux_Dmgd', 'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    \n",
    "    return extracted_data\n",
    "# Load data for 2010\n",
    "fires_2010 = load_wildfire_data(file_2010, sheets, columns_to_extract)\n",
    "# Display the first two rows of the data frame\n",
    "print(\"2010 Fire Data:\")\n",
    "print(fires_2010.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009 Fire Data:\n",
      "           County Fire Name      Start  Contained Acres  Deaths_FF  \\\n",
      "0  San Bernardino      Fort 2009-02-05 2009-02-07   945          0   \n",
      "1      Stanislaus   Mustang 2009-05-13 2009-05-16   570          0   \n",
      "\n",
      "   Deaths_Civil  Duration  \n",
      "0             0       3.0  \n",
      "1             0       4.0  \n"
     ]
    }
   ],
   "source": [
    "#  PART 5: EXTRACT DATA FOR 2009 FIRES:\n",
    "\n",
    "# Define path to the source file of fires 2009\n",
    "file_2009 = 'Resources/CAL_FireStats/2009-wildfire-activity-stats.xlsx'\n",
    "# Define the sheets to be read thta contain needed information (different number of pages than 2016, 2018-2019 files)\n",
    "sheets = ['table_page_15', 'table_page_16', 'table_page_17', 'table_page_18']\n",
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                        'Fire', 'Civil']\n",
    "# Function to load and process the data from the given Excel file\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    extracted_data = pd.DataFrame()\n",
    "    \n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres',\n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                    'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    \n",
    "    return extracted_data\n",
    "# Load data for 2009\n",
    "fires_2009 = load_wildfire_data(file_2009, sheets, columns_to_extract)\n",
    "# Display the first two rows of the data frame\n",
    "print(\"2009 Fire Data:\")\n",
    "print(fires_2009.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008 Fire Data:\n",
      "           County Fire Name      Start  Contained  Acres  Deaths_FF  \\\n",
      "0  San Bernardino     Bluff 2008-03-16 2008-03-20    680          0   \n",
      "1    Tehama-Glenn   Colyear 2008-05-06 2008-05-09  1,331          0   \n",
      "\n",
      "   Deaths_Civil  Duration  \n",
      "0             0       5.0  \n",
      "1             0       4.0  \n"
     ]
    }
   ],
   "source": [
    "#  PART 6: EXTRACT DATA FOR 2008 FIRES:\n",
    "\n",
    "# Define path to the source file of fires 2008\n",
    "file_2008 = 'Resources/CAL_FireStats/2008-wildfire-activity-stats.xlsx'\n",
    "# Define the sheets to be read thta contain needed information (different number of pages than 2016, 2018-2019 files)\n",
    "sheets = ['table_page_15', 'table_page_16', 'table_page_17', 'table_page_18', 'table_page_19', 'table_page_20', 'table_page_21', 'table_page_22']\n",
    "# Define the columns to be extracted\n",
    "columns_to_extract = ['County', 'Fire Name', 'Start', 'Cont.', 'Total', \n",
    "                        'Fire', 'Civil']\n",
    "# Function to load and process the data from the given Excel file\n",
    "def load_wildfire_data(file_path, sheets, columns_to_extract):\n",
    "    extracted_data = pd.DataFrame()\n",
    "    \n",
    "    for sheet_name in sheets:\n",
    "        data = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=1, usecols=columns_to_extract)\n",
    "        extracted_data = pd.concat([extracted_data, data], ignore_index=True)\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Start' and 'Cont.' columns to datetime format\n",
    "    extracted_data['Start'] = pd.to_datetime(extracted_data['Start'])\n",
    "    extracted_data['Cont.'] = pd.to_datetime(extracted_data['Cont.'])\n",
    "    \n",
    "    # 'TRANSFORM': Convert 'Fire', and 'Civil' columns to integers and replace NaN values with zero\n",
    "    extracted_data['Fire'] = pd.to_numeric(extracted_data['Fire'], errors='coerce').fillna(0).astype(int)\n",
    "    extracted_data['Civil'] = pd.to_numeric(extracted_data['Civil'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # Rename columns\n",
    "    extracted_data = extracted_data.rename(columns={'Cont.': \"Contained\", 'Total': 'Acres',\n",
    "                                                    'Fire': 'Deaths_FF', 'Civil': 'Deaths_Civil'})\n",
    "    \n",
    "    # Create a new column 'Duration' that calculates the number of days between 'Start' and 'Contained'\n",
    "    extracted_data['Duration'] = (extracted_data['Contained'] - extracted_data['Start']).dt.days + 1\n",
    "\n",
    "    # Reorder columns\n",
    "    extracted_data = extracted_data[['County', 'Fire Name', 'Start', 'Contained', 'Acres', \n",
    "                                    'Deaths_FF', 'Deaths_Civil', 'Duration']]\n",
    "    \n",
    "    return extracted_data\n",
    "# Load data for 2008\n",
    "fires_2008 = load_wildfire_data(file_2008, sheets, columns_to_extract)\n",
    "# Display the first two rows of the data frame\n",
    "print(\"2008 Fire Data:\")\n",
    "print(fires_2008.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PART 7:  Combine the data from 2008 to 2019\n",
    "fires_2008_2019= pd.concat([fires_2008, fires_2009, fires_2010, fires_2014, fires_2015, fires_2017, fires_2011_2012_2013_2016_2018_2019_data], ignore_index=True)\n",
    "                           \n",
    "# The file is not saved to csv as further dart clean up and concatenation will be executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 2020-2022 data with 2008-2019 data frame\n",
    "# Read the file\n",
    "fires_2020_2022 = pd.read_csv('Outputs/fires_2020_2022.csv')\n",
    "# Concatenate the two DataFrames\n",
    "fires_2008_2022 = pd.concat([fires_2008_2019, fires_2020_2022], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where 'Start' is after 'Cont.':\n",
      "        County Fire Name                Start            Contained  Acres  \\\n",
      "259   Tuolumne     SLOPE  2010-07-25 00:00:00  2010-01-23 00:00:00  1,711   \n",
      "798     TEHAMA      DALE  2028-07-09 00:00:00  2018-07-09 00:00:00    856   \n",
      "1021    FRESNO     EAGLE           2020-06-15           2020-06-13    300   \n",
      "\n",
      "      Deaths_FF  Deaths_Civil  Duration  Strux_Destr  Strux_Dmgd  \n",
      "259           0             0    -182.0          0.0         0.0  \n",
      "798           0             0   -3652.0          0.0         0.0  \n",
      "1021          0             0      -1.0          0.0         0.0  \n"
     ]
    }
   ],
   "source": [
    "# PART 8: FINAL CLEAN UP OF THE COMBINED DATA 2008 - 2022\n",
    "\n",
    "# Sort the final data by the start and then contained dates (in case of multiple fires started on the same date)\n",
    "fires_2008_2022_sorted = fires_2008_2022.sort_values(by=['Start', 'Contained'], ascending=True)\n",
    "\n",
    "# Remove rows where 'County' column is empty (NaN or empty strings) to remove summary lines from the data\n",
    "fires_2008_2022_filtered = fires_2008_2022_sorted.dropna(subset=['County']) # Remove Nan values\n",
    "fires_2008_2022_filtered = fires_2008_2022_filtered[fires_2008_2022_filtered['County'].str.strip() != ''] #Remove empty lines\n",
    "\n",
    "# Identify where 'Start' is after 'Cont.'\n",
    "incorrect_dates = fires_2008_2022_filtered[fires_2008_2022_filtered['Start'] > fires_2008_2022_filtered['Contained']]\n",
    "\n",
    "# Display the rows where 'Start' is after 'Cont.'\n",
    "if not incorrect_dates.empty:\n",
    "    print(\"Rows where 'Start' is after 'Cont.':\")\n",
    "    print(incorrect_dates)\n",
    "else:\n",
    "        print(\"No rows found where 'Start' is after 'Cont.'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Start  Contained\n",
      "259  2010-07-25 2010-08-23\n",
      "798  2017-07-09 2018-07-09\n",
      "1021 2020-06-15 2020-06-15\n"
     ]
    }
   ],
   "source": [
    "# The records  above indicate incorrect dates (fire can't start after 'contained' date.)\n",
    "# Correcting dates based on verified historical records:\n",
    "\n",
    "# Correcting records based on verified fire dates (via Google and Chat GPT)\n",
    "fires_2008_2022_filtered.at[798, 'Start'] = '2017-07-09'\n",
    "fires_2008_2022_filtered.at[259, 'Contained'] = '2010-08-23'\n",
    "fires_2008_2022_filtered.at[1021, 'Contained'] = '2020-06-15'\n",
    "\n",
    "# Ensure that the changes are in datetime format\n",
    "fires_2008_2022_filtered['Start'] = pd.to_datetime(fires_2008_2022_filtered['Start'], errors='coerce')\n",
    "fires_2008_2022_filtered['Contained'] = pd.to_datetime(fires_2008_2022_filtered['Contained'], errors='coerce')\n",
    "\n",
    "# Check if the corrections were successful\n",
    "print(fires_2008_2022_filtered.loc[[259, 798, 1021], ['Start', 'Contained']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start        datetime64[ns]\n",
      "Contained    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data type of 'Start' and 'Contained' columns\n",
    "print(fires_2008_2022_filtered[['Start', 'Contained']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors were found in fire duration count.\n",
      "         Start  Contained  Duration\n",
      "945 2022-09-07 2022-09-14       8.0\n",
      "947 2022-09-07 2022-09-28      22.0\n",
      "99         NaT        NaT       NaN\n",
      "187        NaT        NaT       NaN\n",
      "251        NaT        NaT       NaN\n"
     ]
    }
   ],
   "source": [
    "# Sort the cleaned data by 'Start' and 'Contained' dates\n",
    "fires_2008_2022_cleaned = fires_2008_2022_filtered.sort_values(by=['Start', 'Contained'], ascending=True)\n",
    "\n",
    "# Calculate the duration of the fire \n",
    "fires_2008_2022_cleaned['Duration'] = (fires_2008_2022_cleaned['Contained'] - fires_2008_2022_cleaned['Start']).dt.days + 1\n",
    "\n",
    "# Look for cases where 'Contained' date is before 'Start' date\n",
    "fires_2008_2022_cleaned.loc[fires_2008_2022_cleaned['Duration'] < 0, 'Duration'] = 1\n",
    "\n",
    "# Display the rows where 'Duration' is negative to identify data issues\n",
    "negative_duration = fires_2008_2022_cleaned[fires_2008_2022_cleaned['Duration'] < 0]\n",
    "if not negative_duration.empty:\n",
    "    print(\"Duration is incorrect:\")\n",
    "    print(negative_duration)\n",
    "else:\n",
    "    print(\"No errors were found in fire duration count.\")\n",
    "\n",
    "# Print the cleaned data to verify no errors\n",
    "print(fires_2008_2022_cleaned[['Start', 'Contained', 'Duration']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of the remaining rows with NaT in 'Start', 'Contained', or 'Duration' is equal to: 0\n",
      "         Start  Contained  Duration\n",
      "943 2022-09-02 2022-10-30      59.0\n",
      "944 2022-09-05 2022-09-22      18.0\n",
      "946 2022-09-06 2022-10-22      47.0\n",
      "945 2022-09-07 2022-09-14       8.0\n",
      "947 2022-09-07 2022-09-28      22.0\n"
     ]
    }
   ],
   "source": [
    "# Display above shows summary lines (lines with NaN values) are included our combined data\n",
    "\n",
    "# Remove rows where 'Start', 'Contained', or 'Duration' columns have NaT values\n",
    "fires_2008_2022_cleaned = fires_2008_2022_cleaned.dropna(subset=['Start', 'Contained', 'Duration'])\n",
    "\n",
    "# Check if the removal went successul\n",
    "remaining_nat_records = fires_2008_2022_cleaned[fires_2008_2022_cleaned[['Start', 'Contained', 'Duration']].isna().any(axis=1)]\n",
    "print(f\"The number of the remaining rows with NaT in 'Start', 'Contained', or 'Duration' is equal to: {len(remaining_nat_records)}\")\n",
    "\n",
    "# Print the cleaned data to verify all was corrected\n",
    "print(fires_2008_2022_cleaned[['Start', 'Contained', 'Duration']].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspiciously long durations:\n",
      "        County  Fire Name      Start  Contained   Acres  Deaths_FF  \\\n",
      "146   MONTEREY      CHALK 2008-09-25 2028-10-29  16,269          0   \n",
      "645   MARIPOSA    CASCADE 2012-06-16 2012-11-26   1,705          0   \n",
      "798     TEHAMA       DALE 2017-07-09 2018-07-09     856          0   \n",
      "860     COLUSA       SAND 2019-06-08 2020-06-15   2,220          0   \n",
      "958     TULARE  SUCCESS 2 2020-06-18 2021-06-21     800          0   \n",
      "1119  SISKIYOU      DEVIL 2020-09-09 2050-11-15   8,857          0   \n",
      "\n",
      "      Deaths_Civil  Duration  Strux_Destr  Strux_Dmgd  \n",
      "146              0    7340.0          NaN         NaN  \n",
      "645              0     164.0          0.0         0.0  \n",
      "798              0     366.0          0.0         0.0  \n",
      "860              0     374.0          4.0         0.0  \n",
      "958              0     369.0          0.0         0.0  \n",
      "1119             0   11025.0          0.0         0.0  \n"
     ]
    }
   ],
   "source": [
    "# Verifying if there are any other errors in the data (like suspiciously long fires)\n",
    "\n",
    "# Define the threshold duration in days\n",
    "threshold_duration = 150\n",
    "# Find and display if any fires lasted longer than 150 days according to our data\n",
    "long_durations = fires_2008_2022_cleaned[fires_2008_2022_cleaned['Duration'] > threshold_duration]\n",
    "print(\"Suspiciously long durations:\")\n",
    "print(long_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected records:\n",
      "        County  Fire Name      Start  Contained   Acres  Deaths_FF  \\\n",
      "146   MONTEREY      CHALK 2008-09-25 2008-10-29  16,269          0   \n",
      "645   MARIPOSA    CASCADE 2012-06-18 2012-11-26   1,705          0   \n",
      "798     TEHAMA       DALE 2017-06-24 2017-06-26     856          0   \n",
      "860     COLUSA       SAND 2019-06-08 2019-06-15   2,220          0   \n",
      "958     TULARE  SUCCESS 2 2020-06-18 2020-06-19     800          0   \n",
      "1119  SISKIYOU      DEVIL 2020-09-09 2020-11-07   8,857          0   \n",
      "\n",
      "      Deaths_Civil  Duration  Strux_Destr  Strux_Dmgd  \n",
      "146              0    7340.0          NaN         NaN  \n",
      "645              0     164.0          0.0         0.0  \n",
      "798              0     366.0          0.0         0.0  \n",
      "860              0     374.0          4.0         0.0  \n",
      "958              0     369.0          0.0         0.0  \n",
      "1119             0   11025.0          0.0         0.0  \n"
     ]
    }
   ],
   "source": [
    "# Correct the dates of long fires that do not match Google reserch\n",
    "fires_2008_2022_cleaned.loc[146, 'Contained'] = fires_2008_2022_cleaned.loc[146, 'Contained'].replace(year=2008)\n",
    "fires_2008_2022_cleaned.at[645, 'Start'] = '2012-06-18'\n",
    "fires_2008_2022_cleaned.at[798, 'Start'] = '2017-06-24'\n",
    "fires_2008_2022_cleaned.at[798, 'Contained'] = '2017-06-26'\n",
    "fires_2008_2022_cleaned.loc[860, 'Contained'] = fires_2008_2022_cleaned.loc[860, 'Contained'].replace(year=2019)\n",
    "fires_2008_2022_cleaned.at[958, 'Contained'] = fires_2008_2022_cleaned.loc[956, 'Contained'].replace(year=2020)\n",
    "fires_2008_2022_cleaned.at[1119, 'Contained'] = '2020-09-06'\n",
    "fires_2008_2022_cleaned.at[1119, 'Contained'] = '2020-11-07'\n",
    "\n",
    "# Ensure that the changes are in datetime format\n",
    "fires_2008_2022_cleaned['Start'] = pd.to_datetime(fires_2008_2022_cleaned['Start'], errors='coerce')\n",
    "fires_2008_2022_cleaned['Contained'] = pd.to_datetime(fires_2008_2022_cleaned['Contained'], errors='coerce')\n",
    "\n",
    "\n",
    "# Verify the updated record\n",
    "print(\"Corrected records:\")\n",
    "print(fires_2008_2022_cleaned.loc[[146, 645, 798, 860, 958, 1119]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "County                     MONTEREY\n",
      "Fire Name                     CHALK\n",
      "Start           2008-09-25 00:00:00\n",
      "Contained       2008-10-29 00:00:00\n",
      "Acres                        16,269\n",
      "Deaths_FF                         0\n",
      "Deaths_Civil                      0\n",
      "Duration                     7340.0\n",
      "Strux_Destr                       0\n",
      "Strux_Dmgd                        0\n",
      "Name: 146, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 'TRANSFORM': Convert 'Strux_Destr', 'Strux_Dmgd' columns to integers and replace NaN values with zero\n",
    "fires_2008_2022_cleaned['Strux_Destr'] = pd.to_numeric(fires_2008_2022_cleaned['Strux_Destr'], errors='coerce').fillna(0).astype(int)\n",
    "fires_2008_2022_cleaned['Strux_Dmgd'] = pd.to_numeric(fires_2008_2022_cleaned['Strux_Dmgd'], errors='coerce').fillna(0).astype(int)\n",
    "print(fires_2008_2022_cleaned.loc[146])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "Updated DataFrame with recalculated Duration:\n",
      "             County              Fire Name      Start  Contained  Acres  \\\n",
      "100            LAKE  CONTROL BURN, GEYSERS 2008-02-13 2008-02-13    400   \n",
      "0    San Bernardino                  Bluff 2008-03-16 2008-03-20    680   \n",
      "101        MARIPOSA              WAWONA NW 2008-04-09 2008-04-19  1,130   \n",
      "102     LOS ANGELES            SANTA ANITA 2008-04-26 2008-05-02    584   \n",
      "103       RIVERSIDE                 APACHE 2008-04-29 2008-05-04    769   \n",
      "\n",
      "     Deaths_FF  Deaths_Civil  Duration  Strux_Destr  Strux_Dmgd  \n",
      "100          0             0         1            0           0  \n",
      "0            0             0         5            0           0  \n",
      "101          0             0        11            0           0  \n",
      "102          0             0         7            0           0  \n",
      "103          0             0         6            0           0  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'Start' and 'Contained' columns to datetime to correct the duration after changing fire dates in the code above\n",
    "fires_2008_2022_cleaned['Start'] = pd.to_datetime(fires_2008_2022_cleaned['Start'])\n",
    "fires_2008_2022_cleaned['Contained'] = pd.to_datetime(fires_2008_2022_cleaned['Contained'])\n",
    "\n",
    "# Recalculate the 'Duration' for the entire DataFrame\n",
    "# Add 1 day to account for the inclusive nature of start and contained dates\n",
    "fires_2008_2022_cleaned['Duration'] = (fires_2008_2022_cleaned['Contained'] - fires_2008_2022_cleaned['Start']).dt.days + 1\n",
    "\n",
    "# Check the dtype to verify the conversion\n",
    "print(fires_2008_2022_cleaned['Duration'].dtype)\n",
    "\n",
    "# Print the updated DataFrame to verify the recalculated 'Duration'\n",
    "print(\"Updated DataFrame with recalculated Duration:\")\n",
    "print(fires_2008_2022_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties that do not match the valid list:\n",
      "                                      County\n",
      "1                               TEHAMA-GLENN\n",
      "2                               FRESNO-KINGS\n",
      "3                               FRESNO-KINGS\n",
      "6                           SONOMA-LAKE-NAPA\n",
      "9                           MARDERA-MARIPOSA\n",
      "...                                      ...\n",
      "1105                           PLUMAS, BUTTE\n",
      "1113                          FRESNO, MADERA\n",
      "1070                            NAPA, SONOMA\n",
      "965   PLUMAS, BUTTE, LASSEN,\\nSHASTA, TEHAMA\n",
      "946                       PLACER,\\nEL DORADO\n",
      "\n",
      "[90 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check if any county are misspelled \n",
    "# List of valid county names\n",
    "valid_counties = [\n",
    "    'ALAMEDA', 'ALPINE', 'AMADOR', 'BUTTE', 'CALAVERAS', 'COLUSA', 'CONTRA COSTA', \n",
    "    'DEL NORTE', 'EL DORADO', 'FRESNO', 'GLENN', 'HUMBOLDT', 'IMPERIAL', 'INYO', \n",
    "    'KERN', 'KINGS', 'LAKE', 'LASSEN', 'LOS ANGELES', 'MADERA', 'MARIN', 'MARIPOSA', \n",
    "    'MENDOCINO', 'MERCED', 'MODOC', 'MONO', 'MONTEREY', 'NAPA', 'NEVADA', 'ORANGE', \n",
    "    'PLACER', 'PLUMAS', 'RIVERSIDE', 'SACRAMENTO', 'SAN BENITO', 'SAN BERNARDINO', \n",
    "    'SAN DIEGO', 'SAN FRANCISCO', 'SAN JOAQUIN', 'SAN LUIS OBISPO', 'SAN MATEO', \n",
    "    'SANTA BARBARA', 'SANTA CLARA', 'SANTA CRUZ', 'SHASTA', 'SIERRA', 'SISKIYOU', \n",
    "    'SOLANO', 'SONOMA', 'STANISLAUS', 'SUTTER', 'TEHAMA', 'TRINITY', 'TULARE', \n",
    "    'TUOLUMNE', 'VENTURA', 'YOLO', 'YUBA', 'JACKSON (OR)', 'WASHOE (NV)'\n",
    "]\n",
    "# Convert the 'County' column to uppercase to ensure matching\n",
    "fires_2008_2022_cleaned['County'] = fires_2008_2022_cleaned['County'].str.upper()\n",
    "\n",
    "# Find counties that are not in the valid counties list\n",
    "invalid_counties = fires_2008_2022_cleaned[~fires_2008_2022_cleaned['County'].isin(valid_counties)]\n",
    "\n",
    "# Display the rows with invalid counties\n",
    "print(\"Counties that do not match the valid list:\")\n",
    "print(invalid_counties[['County']])\n",
    "# Saving incorrect list of misspelled counties for review\n",
    "invalid_counties.to_csv('Outputs/invalid_counties.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90 rows were not identified correctly (please see the output above)\n",
    "\n",
    "# Define a function to clean up the 'County' column\n",
    "def clean_county_name(county_name):\n",
    "    # Remove text after '-', ',', and '/' and strip any extra whitespace\n",
    "    return county_name.split('-')[0].split(',')[0].split('/')[0].split('\\\\')[0].split('\\\\n')[0].strip()\n",
    "\n",
    "# Apply the cleaning function to the 'County' column\n",
    "fires_2008_2022_cleaned['County'] = fires_2008_2022_cleaned['County'].apply(clean_county_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with your corrections dictionary for specific misspellings\n",
    "corrections = {\n",
    "    'TAHEMA': 'TEHAMA',\n",
    "    'ELDORADO': 'EL DORADO',\n",
    "    'TEHEMA': 'TEHAMA',\n",
    "    'TOULUMNE': 'TUOLUMNE',\n",
    "    'TUOLOMNE': 'TUOLUMNE',\n",
    "    'WASHOE': 'WASHOE (NV)',\n",
    "    'VANDENBURG AFB': 'SANTA BARBARA',\n",
    "    'MARDERA': 'MADERA',\n",
    "    'VENTURA/SANTA\\nBARBARA': 'VENTURA',\n",
    "    'COLUSA, GLENN,\\nLAKE, MENDOCINO': 'COLUSA',\n",
    "    'COLUSA, LAKE,\\nMENDOCINO': 'COLUSA',\n",
    "    'SANTA\\nBARBARA': 'SANTA BARBARA',\n",
    "    'SAN LUIS\\nOBISPO': 'SAN LUIS OBISPO',\n",
    "    'SAN\\nBERNARDINO': 'SAN BERNARDINO',\n",
    "    'VANDENBURG AFB': 'SANTA BARBARA'\n",
    "}\n",
    "\n",
    "# Apply the corrections to the 'County' column\n",
    "fires_2008_2022_cleaned['County'] = fires_2008_2022_cleaned['County'].replace(corrections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counties that do not match the valid list:\n",
      "Empty DataFrame\n",
      "Columns: [County]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Find counties that are not in the valid counties list\n",
    "invalid_counties_test = fires_2008_2022_cleaned[~fires_2008_2022_cleaned['County'].isin(valid_counties)]\n",
    "\n",
    "# Display the rows with invalid counties\n",
    "print(\"Counties that do not match the valid list:\")\n",
    "print(invalid_counties_test[['County']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        County Fire Name      Start  Contained   Acres  Deaths_FF  \\\n",
      "943   SISKIYOU  MOUNTAIN 2022-09-02 2022-10-30  13,440          0   \n",
      "944  RIVERSIDE  FAIRVIEW 2022-09-05 2022-09-22  28,098          0   \n",
      "946     PLACER  MOSQUITO 2022-09-06 2022-10-22  76,788          0   \n",
      "945     MADERA      FORK 2022-09-07 2022-09-14     819          0   \n",
      "947      MODOC    BARNES 2022-09-07 2022-09-28   5,843          0   \n",
      "\n",
      "     Deaths_Civil  Duration  Strux_Destr  Strux_Dmgd  \n",
      "943             0        59            4           0  \n",
      "944             2        18           37           8  \n",
      "946             0        47           78          14  \n",
      "945             0         8           43           1  \n",
      "947             0        22            2           0  \n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned data to the \"Outputs\" folder\n",
    "fires_2008_2022_cleaned.to_csv('Outputs/fires_2008_2022_cleaned.csv', index=False)\n",
    "\n",
    "# Print the cleaned data to check\n",
    "print(fires_2008_2022_cleaned.tail(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
